{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Requires PySpark, installation information can be found here: https://www.dataquest.io/blog/installing-pyspark/\n",
    "#import PySpark as ps \n",
    "import feedparser as fp, pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "#Get the News Feed and Slice it to only include the news items\n",
    "feed = fp.parse('http://feeds.huffingtonpost.com/c/35496/f/677097/index.rss')\n",
    "feed_items = feed['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daryl Deino</td>\n",
       "      <td>http://www.huffingtonpost.com/daryl-deino/senn...</td>\n",
       "      <td>Sennheiser M2 Wireless Headphones Are Best Blu...</td>\n",
       "      <td>Photo by Daryl Deino  The Sennheiser M2 Wirel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy Plesser</td>\n",
       "      <td>http://www.huffingtonpost.com/andy-plesser/vid...</td>\n",
       "      <td>(VIDEO) OpenX Hoping To Optimize The Use Of Mu...</td>\n",
       "      <td>The increased popularity of header bidding has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Damon Beres</td>\n",
       "      <td>http://www.huffingtonpost.com/2016/03/29/distr...</td>\n",
       "      <td>Sending A Text Behind The Wheel Is Like Drivin...</td>\n",
       "      <td>If you look at your phone for just four secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andy Plesser</td>\n",
       "      <td>http://www.huffingtonpost.com/andy-plesser/vid...</td>\n",
       "      <td>(VIDEO) The Trade Desk Rolling Out Programmati...</td>\n",
       "      <td>MIAMI - Demand-side platform The Trade Desk be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erin Schumaker</td>\n",
       "      <td>http://www.huffingtonpost.com/2016/03/29/telem...</td>\n",
       "      <td>The Tech Innovation That Might Make It Easier ...</td>\n",
       "      <td>(Reuters Health) - Women in the U.S. without ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                                 id  \\\n",
       "0     Daryl Deino  http://www.huffingtonpost.com/daryl-deino/senn...   \n",
       "1    Andy Plesser  http://www.huffingtonpost.com/andy-plesser/vid...   \n",
       "2     Damon Beres  http://www.huffingtonpost.com/2016/03/29/distr...   \n",
       "3    Andy Plesser  http://www.huffingtonpost.com/andy-plesser/vid...   \n",
       "4  Erin Schumaker  http://www.huffingtonpost.com/2016/03/29/telem...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Sennheiser M2 Wireless Headphones Are Best Blu...   \n",
       "1  (VIDEO) OpenX Hoping To Optimize The Use Of Mu...   \n",
       "2  Sending A Text Behind The Wheel Is Like Drivin...   \n",
       "3  (VIDEO) The Trade Desk Rolling Out Programmati...   \n",
       "4  The Tech Innovation That Might Make It Easier ...   \n",
       "\n",
       "                                             summary  \n",
       "0   Photo by Daryl Deino  The Sennheiser M2 Wirel...  \n",
       "1  The increased popularity of header bidding has...  \n",
       "2   If you look at your phone for just four secon...  \n",
       "3  MIAMI - Demand-side platform The Trade Desk be...  \n",
       "4   (Reuters Health) - Women in the U.S. without ...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################Create the Cleaned News Items DataFrame###########################################\n",
    "\n",
    "#Import the raw data into a DataFrame\n",
    "raw_news_dataframe = pd.DataFrame(feed_items)\n",
    "\n",
    "#Clean the DataFrame\n",
    "def dataframe_cleaner(dataframe): \n",
    "    being_cleaned_df = pd.DataFrame(raw_news_dataframe[['author','id','title','summary']])\n",
    "    \n",
    "    for i in range(0,len(being_cleaned_df['summary'])):\n",
    "        soup = BeautifulSoup(being_cleaned_df['summary'][i],'lxml')\n",
    "        being_cleaned_df['summary'][i] = soup.get_text()\n",
    "    \n",
    "    return being_cleaned_df\n",
    "    \n",
    "#Create the cleaned Dataframe    \n",
    "news_df = dataframe_cleaner(raw_news_dataframe)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8222\n",
      "8222\n",
      "[ 0.5  1. ] [-1  1  0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>word</th>\n",
       "      <th>position</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>adj</td>\n",
       "      <td>n</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type       word position stemmed  polarity\n",
       "0   0.5  abandoned      adj       n        -1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################Import, Clean and DataFrame the Sentiment Dictionary################################\n",
    "\n",
    "#Import the Sentiment Dictionary \n",
    "f = open('sentiment_dictionary.tff','r')\n",
    "raw_sentiment_dictionary = f.read()\n",
    "\n",
    "\n",
    "#Create a Totally Cleaned Sentiment Dataframe\n",
    "def sentiment_dataframe_maker(file):\n",
    "    \n",
    "    #Call another function to turn the file into a raw dataframe\n",
    "    raw_df = dictionary_to_dataframe(file)\n",
    "    raw_df = raw_df.dropna()\n",
    "    #Clean up the strings within the cells\n",
    "    replace_list = ['type','word','position','stemmed','polarity']\n",
    "    \n",
    "    for x in replace_list:\n",
    "        raw_df[x] = list(map(lambda x: x.split('=')[-1],raw_df[x]))\n",
    "        \n",
    "    #Convert Type and Polarity to numerical values \n",
    "    \n",
    "    type_unique = dict.fromkeys(raw_df['type'].unique())\n",
    "    type_unique['weaksubj'] = .5\n",
    "    type_unique['strongsubj'] = 1\n",
    "    \n",
    "    for key,value in type_unique.items():\n",
    "        raw_df['type'] = raw_df['type'].replace(key,value)  \n",
    "    \n",
    "    polarity_unique = dict.fromkeys(raw_df['polarity'].unique())\n",
    "    polarity_unique['negative'] = int(-1)\n",
    "    polarity_unique['positive'] = int(1)\n",
    "    polarity_unique['neutral'] = 0\n",
    "    polarity_unique['both'] = None\n",
    "    polarity_unique['m'] = None\n",
    "    \n",
    "    for key,value in polarity_unique.items():\n",
    "        raw_df['polarity'] = raw_df['polarity'].replace(key,value)\n",
    "    \n",
    "    raw_df = raw_df.dropna()\n",
    "    \n",
    "    return raw_df\n",
    "    \n",
    "    \n",
    "    \n",
    "#Cleanse the Dictionary and create a Raw Sentiment DataFrame\n",
    "def dictionary_to_dataframe(dictionary):\n",
    "    \n",
    "    being_cleaned_list = dictionary.split('\\n')\n",
    "    being_cleaned_list = [x.split(',') for x in being_cleaned_list]\n",
    "    being_cleaned_list = list(map(lambda x: x[0].split(\" \"),being_cleaned_list))\n",
    "    being_cleaned_df = pd.DataFrame(being_cleaned_list)\n",
    "    being_cleaned_df = being_cleaned_df[[0,2,3,4,5]]\n",
    "    being_cleaned_df.columns = ['type','word','position','stemmed','polarity']\n",
    "    \n",
    "    return being_cleaned_df\n",
    "    \n",
    "\n",
    "    \n",
    "sentiment_df = sentiment_dataframe_maker(raw_sentiment_dictionary)\n",
    "sentiment_df.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
