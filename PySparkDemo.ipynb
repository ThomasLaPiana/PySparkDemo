{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Requires PySpark, installation information can be found here: https://www.dataquest.io/blog/installing-pyspark/\n",
    "#import PySpark as ps \n",
    "import feedparser as fp, pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "#Get the News Feed and Slice it to only include the news items\n",
    "feed = fp.parse('http://feeds.huffingtonpost.com/c/35496/f/677097/index.rss')\n",
    "feed_items = feed['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Damon Beres</td>\n",
       "      <td>http://www.huffingtonpost.com/2016/03/29/iqos-...</td>\n",
       "      <td>Big Tobacco Is Starting To Cash In On Vaping</td>\n",
       "      <td>TOKYO (Reuters) - Two tobacco giants are seei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fred Raillard</td>\n",
       "      <td>http://www.huffingtonpost.com/fred-raillard-/f...</td>\n",
       "      <td>#FredinChina: Taobao Latest Campaign Is All Ab...</td>\n",
       "      <td>I'm Fred Raillard, CEO, Co-founder and Creativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Conversation US</td>\n",
       "      <td>http://www.huffingtonpost.com/the-conversation...</td>\n",
       "      <td>We Don't Talk Much About Nanotechnology Risks ...</td>\n",
       "      <td>Andrew Maynard, Arizona State University   Va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>http://www.huffingtonpost.com/2016/03/28/shahe...</td>\n",
       "      <td>Mysterious Stacks Of Books In NYC Are Connecti...</td>\n",
       "      <td>Could this be a new chapter in the way we int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Victoria Espinel</td>\n",
       "      <td>http://www.huffingtonpost.com/victoria-espinel...</td>\n",
       "      <td>A Bipartisan, Consensus Approach to Innovation...</td>\n",
       "      <td>In encouraging news given today's climate, Con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                                 id  \\\n",
       "0          Damon Beres  http://www.huffingtonpost.com/2016/03/29/iqos-...   \n",
       "1        Fred Raillard  http://www.huffingtonpost.com/fred-raillard-/f...   \n",
       "2  The Conversation US  http://www.huffingtonpost.com/the-conversation...   \n",
       "3        Elyse Wanshel  http://www.huffingtonpost.com/2016/03/28/shahe...   \n",
       "4     Victoria Espinel  http://www.huffingtonpost.com/victoria-espinel...   \n",
       "\n",
       "                                               title  \\\n",
       "0       Big Tobacco Is Starting To Cash In On Vaping   \n",
       "1  #FredinChina: Taobao Latest Campaign Is All Ab...   \n",
       "2  We Don't Talk Much About Nanotechnology Risks ...   \n",
       "3  Mysterious Stacks Of Books In NYC Are Connecti...   \n",
       "4  A Bipartisan, Consensus Approach to Innovation...   \n",
       "\n",
       "                                             summary  \n",
       "0   TOKYO (Reuters) - Two tobacco giants are seei...  \n",
       "1  I'm Fred Raillard, CEO, Co-founder and Creativ...  \n",
       "2   Andrew Maynard, Arizona State University   Va...  \n",
       "3   Could this be a new chapter in the way we int...  \n",
       "4  In encouraging news given today's climate, Con...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the raw data into a DataFrame\n",
    "raw_news_dataframe = pd.DataFrame(feed_items)\n",
    "\n",
    "#Clean the DataFrame\n",
    "def dataframe_cleaner(dataframe): \n",
    "    being_cleaned_df = pd.DataFrame(raw_news_dataframe[['author','id','title','summary']])\n",
    "    \n",
    "    for i in range(0,len(being_cleaned_df['summary'])):\n",
    "        soup = BeautifulSoup(being_cleaned_df['summary'][i],'lxml')\n",
    "        being_cleaned_df['summary'][i] = soup.get_text()\n",
    "    \n",
    "    return being_cleaned_df\n",
    "    \n",
    "#Create the cleaned Dataframe    \n",
    "news_df = dataframe_cleaner(raw_news_dataframe)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "      <th>word</th>\n",
       "      <th>position</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type=weaksubj</td>\n",
       "      <td>len=1</td>\n",
       "      <td>word1=abandoned</td>\n",
       "      <td>pos1=adj</td>\n",
       "      <td>stemmed1=n</td>\n",
       "      <td>priorpolarity=negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type=weaksubj</td>\n",
       "      <td>len=1</td>\n",
       "      <td>word1=abandonment</td>\n",
       "      <td>pos1=noun</td>\n",
       "      <td>stemmed1=n</td>\n",
       "      <td>priorpolarity=negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type=weaksubj</td>\n",
       "      <td>len=1</td>\n",
       "      <td>word1=abandon</td>\n",
       "      <td>pos1=verb</td>\n",
       "      <td>stemmed1=y</td>\n",
       "      <td>priorpolarity=negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type=strongsubj</td>\n",
       "      <td>len=1</td>\n",
       "      <td>word1=abase</td>\n",
       "      <td>pos1=verb</td>\n",
       "      <td>stemmed1=y</td>\n",
       "      <td>priorpolarity=negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type=strongsubj</td>\n",
       "      <td>len=1</td>\n",
       "      <td>word1=abasement</td>\n",
       "      <td>pos1=anypos</td>\n",
       "      <td>stemmed1=y</td>\n",
       "      <td>priorpolarity=negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              type length               word     position     stemmed  \\\n",
       "0    type=weaksubj  len=1    word1=abandoned     pos1=adj  stemmed1=n   \n",
       "1    type=weaksubj  len=1  word1=abandonment    pos1=noun  stemmed1=n   \n",
       "2    type=weaksubj  len=1      word1=abandon    pos1=verb  stemmed1=y   \n",
       "3  type=strongsubj  len=1        word1=abase    pos1=verb  stemmed1=y   \n",
       "4  type=strongsubj  len=1    word1=abasement  pos1=anypos  stemmed1=y   \n",
       "\n",
       "                 polarity  \n",
       "0  priorpolarity=negative  \n",
       "1  priorpolarity=negative  \n",
       "2  priorpolarity=negative  \n",
       "3  priorpolarity=negative  \n",
       "4  priorpolarity=negative  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the Sentiment Dictionary \n",
    "f = open('sentiment_dictionary.tff','r')\n",
    "raw_sentiment_dictionary = f.read()\n",
    "\n",
    "\n",
    "#Create a Totally Cleaned Sentiment Dataframe\n",
    "def sentiment_dataframe_maker(file):\n",
    "    #Call another function to turn the file into a raw dataframe\n",
    "    raw_df = dictionary_to_dataframe(file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Cleanse the Dictionary and create a Raw Sentiment DataFrame\n",
    "def dictionary_to_dataframe(dictionary):\n",
    "    being_cleaned_list = dictionary.split('\\n')\n",
    "    being_cleaned_list = [x.split(',') for x in being_cleaned_list]\n",
    "    being_cleaned_list = list(map(lambda x: x[0].split(\" \"),being_cleaned_list))\n",
    "    being_cleaned_list = pd.DataFrame(being_cleaned_list)\n",
    "    being_cleaned_list = being_cleaned_list[[0,1,2,3,4,5]]\n",
    "    being_cleaned_list.columns = ['type','length','word','position','stemmed','polarity']\n",
    "    return being_cleaned_list\n",
    "    \n",
    "\n",
    "    \n",
    "    sentiment_df = sentiment_dataframe_maker(raw_sentiment_dictionary)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
