{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Requires PySpark, installation information can be found here: https://www.dataquest.io/blog/installing-pyspark/\n",
    "#import PySpark as ps \n",
    "import feedparser as fp, pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "#Get the News Feed and Slice it to only include the news items\n",
    "feed = fp.parse('http://feeds.huffingtonpost.com/c/35496/f/677097/index.rss')\n",
    "feed_items = feed['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daryl Deino</td>\n",
       "      <td>http://www.huffingtonpost.com/daryl-deino/senn...</td>\n",
       "      <td>Sennheiser M2 Wireless Headphones Are Best Blu...</td>\n",
       "      <td>Photo by Daryl Deino  The Sennheiser M2 Wirel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                                 id  \\\n",
       "0  Daryl Deino  http://www.huffingtonpost.com/daryl-deino/senn...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Sennheiser M2 Wireless Headphones Are Best Blu...   \n",
       "\n",
       "                                             summary  \n",
       "0   Photo by Daryl Deino  The Sennheiser M2 Wirel...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################Create the Cleaned News Items DataFrame###########################################\n",
    "\n",
    "#Import the raw data into a DataFrame\n",
    "raw_news_dataframe = pd.DataFrame(feed_items)\n",
    "\n",
    "#Clean the DataFrame\n",
    "def dataframe_cleaner(dataframe): \n",
    "    being_cleaned_df = pd.DataFrame(raw_news_dataframe[['author','id','title','summary']])\n",
    "    \n",
    "    for i in range(0,len(being_cleaned_df['summary'])):\n",
    "        soup = BeautifulSoup(being_cleaned_df['summary'][i],'lxml')\n",
    "        being_cleaned_df['summary'][i] = soup.get_text()\n",
    "    \n",
    "    return being_cleaned_df\n",
    "    \n",
    "#Create the cleaned Dataframe    \n",
    "news_df = dataframe_cleaner(raw_news_dataframe)\n",
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>word</th>\n",
       "      <th>position</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>adj</td>\n",
       "      <td>n</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type       word position stemmed  polarity\n",
       "0   0.5  abandoned      adj       n        -1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################Import, Clean and DataFrame the Sentiment Dictionary################################\n",
    "\n",
    "#Import the Sentiment Dictionary \n",
    "f = open('sentiment_dictionary.tff','r')\n",
    "raw_sentiment_dictionary = f.read()\n",
    "\n",
    "\n",
    "#Create a Totally Cleaned Sentiment Dataframe\n",
    "def sentiment_dataframe_maker(file):\n",
    "    \n",
    "    #Call another function to turn the file into a raw dataframe\n",
    "    raw_df = dictionary_to_dataframe(file)\n",
    "    raw_df = raw_df.dropna()\n",
    "    #Clean up the strings within the cells\n",
    "    replace_list = ['type','word','position','stemmed','polarity']\n",
    "    \n",
    "    for x in replace_list:\n",
    "        raw_df[x] = list(map(lambda x: x.split('=')[-1],raw_df[x]))\n",
    "        \n",
    "    #Convert Type and Polarity to numerical values \n",
    "    \n",
    "    type_unique = dict.fromkeys(raw_df['type'].unique())\n",
    "    type_unique['weaksubj'] = .5\n",
    "    type_unique['strongsubj'] = 1\n",
    "    \n",
    "    for key,value in type_unique.items():\n",
    "        raw_df['type'] = raw_df['type'].replace(key,value)  \n",
    "    \n",
    "    polarity_unique = dict.fromkeys(raw_df['polarity'].unique())\n",
    "    polarity_unique['negative'] = int(-1)\n",
    "    polarity_unique['positive'] = int(1)\n",
    "    polarity_unique['neutral'] = 0\n",
    "    polarity_unique['both'] = None\n",
    "    polarity_unique['m'] = None\n",
    "    \n",
    "    for key,value in polarity_unique.items():\n",
    "        raw_df['polarity'] = raw_df['polarity'].replace(key,value)\n",
    "    \n",
    "    raw_df = raw_df.dropna()\n",
    "    \n",
    "    return raw_df\n",
    "    \n",
    "    \n",
    "    \n",
    "#Cleanse the Dictionary and create a Raw Sentiment DataFrame\n",
    "def dictionary_to_dataframe(dictionary):\n",
    "    \n",
    "    being_cleaned_list = dictionary.split('\\n')\n",
    "    being_cleaned_list = [x.split(',') for x in being_cleaned_list]\n",
    "    being_cleaned_list = list(map(lambda x: x[0].split(\" \"),being_cleaned_list))\n",
    "    being_cleaned_df = pd.DataFrame(being_cleaned_list)\n",
    "    being_cleaned_df = being_cleaned_df[[0,2,3,4,5]]\n",
    "    being_cleaned_df.columns = ['type','word','position','stemmed','polarity']\n",
    "    \n",
    "    return being_cleaned_df\n",
    "    \n",
    "\n",
    "#Create the Cleaned Sentiment Dataframe\n",
    "sentiment_df = sentiment_dataframe_maker(raw_sentiment_dictionary)\n",
    "sentiment_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yee ree nee\n"
     ]
    }
   ],
   "source": [
    "##########################Perform Sentiment Analysis on the Title and Body of the Articles#########################\n",
    "def title_sentiment_analysis(title_list):\n",
    "    return 'lel'\n",
    "\n",
    "def summary_sentiment_analysis(summary_list):\n",
    "    return 'kek'\n",
    "\n",
    "def sentiment_analysis(dataframe):\n",
    "    analyzing_df = dataframe\n",
    "    analyzing_df['title_sentiment'] = title_sentiment_analysis(analyzing_df['title'])\n",
    "    analyzing_df['summary_sentiment'] = title_sentiment_analysis(analyzing_df['summary'])\n",
    "    return analyzing_df\n",
    "\n",
    "analyzed_articles_df = sentiment_analysis(news_df)\n",
    "print(analyzed_articles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
