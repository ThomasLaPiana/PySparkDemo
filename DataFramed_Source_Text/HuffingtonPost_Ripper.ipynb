{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################################Imports and Initial Feed Rip###################################################\n",
    "import feedparser as fp, pandas as pd, datetime, time, string, requests as r\n",
    "from bs4 import BeautifulSoup \n",
    "from functools import reduce\n",
    "\n",
    "##TODO - Input these variables\n",
    "\n",
    "rss_feed = 'http://feeds.huffingtonpost.com/c/35496/f/677097/index.rss'\n",
    "company_info_df = pd.read_csv('Target_Company.csv')\n",
    "company_name = company_info_df.iloc[0]['Company Name']\n",
    "ticker_symbol = company_info_df.iloc[0]['Stock Symbol']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Get the News Feed and Slice it to only include the news items\n",
    "feed = fp.parse(rss_feed)\n",
    "feed_items = feed['items']\n",
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrew Hart</td>\n",
       "      <td>http://www.huffingtonpost.com/2016/04/08/us-ap...</td>\n",
       "      <td>U.S. To Keep Fighting For Apple To Unlock iPho...</td>\n",
       "      <td>By Julia Love, Joseph Menn and Nate Raymond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annum Masroor</td>\n",
       "      <td>http://www.huffingtonpost.com/2016/04/08/apple...</td>\n",
       "      <td>Boston Judge Orders Apple To Help Law Enforcem...</td>\n",
       "      <td>BOSTON, April 8 (Reuters) - A U.S. magistrate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kimberly Yam</td>\n",
       "      <td>http://www.huffingtonpost.com/2016/04/08/cooki...</td>\n",
       "      <td>Cookie Monster Is His Best, Zaniest Self In Th...</td>\n",
       "      <td>This reaffirms the fact that we all love Cooki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                                 id  \\\n",
       "0    Andrew Hart  http://www.huffingtonpost.com/2016/04/08/us-ap...   \n",
       "1  Annum Masroor  http://www.huffingtonpost.com/2016/04/08/apple...   \n",
       "2   Kimberly Yam  http://www.huffingtonpost.com/2016/04/08/cooki...   \n",
       "\n",
       "                                               title  \\\n",
       "0  U.S. To Keep Fighting For Apple To Unlock iPho...   \n",
       "1  Boston Judge Orders Apple To Help Law Enforcem...   \n",
       "2  Cookie Monster Is His Best, Zaniest Self In Th...   \n",
       "\n",
       "                                             summary  \n",
       "0     By Julia Love, Joseph Menn and Nate Raymond...  \n",
       "1   BOSTON, April 8 (Reuters) - A U.S. magistrate...  \n",
       "2  This reaffirms the fact that we all love Cooki...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################Create the Cleaned News Items DataFrame###########################################\n",
    "\n",
    "#Import the raw data into a DataFrame\n",
    "raw_news_dataframe = pd.DataFrame(feed_items)\n",
    "\n",
    "#Clean the DataFrame\n",
    "def dataframe_cleaner(dataframe): \n",
    "    being_cleaned_df = pd.DataFrame(raw_news_dataframe[['author','id','title','summary']])\n",
    "    \n",
    "    for i in range(0,len(being_cleaned_df['summary'])):\n",
    "        soup = BeautifulSoup(being_cleaned_df['summary'][i],'lxml')\n",
    "        being_cleaned_df['summary'][i] = soup.get_text()\n",
    "    \n",
    "    return being_cleaned_df\n",
    "    \n",
    "#Create the Full Dataframe    \n",
    "full_df = dataframe_cleaner(raw_news_dataframe)\n",
    ",#Create the filtered dataframe, containing only rows that have company_name in the title\n",
    "company_in_title_list = list(map(lambda x: company_name in x,full_df['title']))\n",
    "news_df = full_df[company_in_title_list].reset_index(drop=True)\n",
    "news_df.head()\n",
    "\n",
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>word</th>\n",
       "      <th>position</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>adj</td>\n",
       "      <td>n</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type       word position stemmed  polarity\n",
       "0   0.5  abandoned      adj       n        -1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load in the Sentiment DataFrame\n",
    "sentiment_df = pd.read_csv('../Sentiment_Dictionary/sentiment_DataFrame.csv')\n",
    "sentiment_df = sentiment_df.ix[:,'type':]\n",
    "sentiment_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 35.689369678497314\n"
     ]
    }
   ],
   "source": [
    "##########################Perform Sentiment Analysis on the Title and Body of the Articles#########################\n",
    "def title_analysis(title):\n",
    "    tokenized_title = dict.fromkeys(title.split(' '))                          \n",
    "                                \n",
    "    for key in tokenized_title:\n",
    "        tokenized_title[key] = [sentiment_df['type'][i] * sentiment_df['polarity'][i]\n",
    "                               for i in range(0,len(sentiment_df.index)) \n",
    "                               if key.lower() == sentiment_df['word'][i]]\n",
    "    \n",
    "    total_sentiment = sum([item for sublist in list(tokenized_title.values()) for item in sublist])\n",
    "    normalized_sentiment = total_sentiment / len(tokenized_title)\n",
    "    \n",
    "    return normalized_sentiment\n",
    "\n",
    "def summary_analysis(summary):\n",
    "    tokenized_summary = dict.fromkeys(summary.split(' '))\n",
    "    \n",
    "    for key in tokenized_summary:\n",
    "        tokenized_summary[key] = [sentiment_df['type'][i] * sentiment_df['polarity'][i]\n",
    "                               for i in range(0,len(sentiment_df.index)) \n",
    "                               if key.lower() == sentiment_df['word'][i]]\n",
    "    \n",
    "    total_sentiment = sum([item for sublist in list(tokenized_summary.values()) for item in sublist])\n",
    "    normalized_sentiment = total_sentiment / len(tokenized_summary)\n",
    "    return normalized_sentiment\n",
    "\n",
    "def sentiment_analysis(dataframe):\n",
    "    analyzing_df = dataframe\n",
    "    analyzing_df['normalized_title_sentiment'] = list(map(lambda x: title_analysis(x),analyzing_df['title']))\n",
    "    analyzing_df['normalized_summary_sentiment'] = list(map(lambda x: summary_analysis(x),analyzing_df['summary']))\n",
    "    return analyzing_df\n",
    "\n",
    "start_time = time.time()\n",
    "analyzed_articles_df = sentiment_analysis(news_df)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Elapsed Time: ' + str(elapsed_time))\n",
    "analyzed_articles_df.head(1)\n",
    "analyzed_articles_df.to_csv('HuffingtonPostSentiment.csv')\n",
    "###################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
